import Handlebars from "handlebars";
import type { ControlMJob } from "@/types/controlm";
import type { AirflowDAG, AirflowTask, AirflowDependency, GeneratedDAG } from "@/types/airflow";

// Register Handlebars helpers
Handlebars.registerHelper("snake_case", (str: string) => {
  if (!str) return "";
  return str
    .replace(/([A-Z])/g, "_$1")
    .replace(/[-\s]+/g, "_")
    .replace(/^_/, "")
    .toLowerCase();
});

Handlebars.registerHelper("camel_case", (str: string) => {
  if (!str) return "";
  return str
    .replace(/[-_\s]+(.)?/g, (_, c) => (c ? c.toUpperCase() : ""))
    .replace(/^(.)/, (c) => c.toLowerCase());
});

Handlebars.registerHelper("quote", (str: string) => {
  if (!str) return '""';
  return `"${str.replace(/"/g, '\\"')}"`;
});

Handlebars.registerHelper("escape_python", (str: string) => {
  if (!str) return "";
  return str.replace(/\\/g, "\\\\").replace(/'/g, "\\'").replace(/"/g, '\\"');
});

// Airflow 2.x DAG Template
const DAG_TEMPLATE_V2 = `"""
Auto-generated Airflow DAG from Control-M
Generated by OFlair
DAG: {{dag_id}}
Airflow Version: 2.x
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.sensors.filesystem import FileSensor

# Default arguments
default_args = {
    'owner': '{{owner}}',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': {{retries}},
    'retry_delay': timedelta(minutes={{retry_delay}}),
}

# DAG definition
with DAG(
    dag_id='{{dag_id}}',
    default_args=default_args,
    description='{{description}}',
    schedule={{schedule}},
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags={{tags}},
) as dag:

{{#each tasks}}
    # Task: {{task_id}}
{{#if is_bash}}
    {{task_id}} = BashOperator(
        task_id='{{task_id}}',
        bash_command='''{{bash_command}}''',
{{#if pool}}
        pool='{{pool}}',
{{/if}}
    )
{{/if}}
{{#if is_python}}
    {{task_id}} = PythonOperator(
        task_id='{{task_id}}',
        python_callable={{python_callable}},
{{#if pool}}
        pool='{{pool}}',
{{/if}}
    )
{{/if}}
{{#if is_sensor}}
    {{task_id}} = FileSensor(
        task_id='{{task_id}}',
        filepath='{{filepath}}',
        poke_interval=60,
        timeout=3600,
        mode='poke',
    )
{{/if}}
{{#if is_empty}}
    {{task_id}} = EmptyOperator(
        task_id='{{task_id}}',
    )
{{/if}}

{{/each}}
    # Dependencies
{{#each dependencies}}
    {{upstream}} >> {{downstream}}
{{/each}}
{{#unless dependencies}}
    # No dependencies defined
    pass
{{/unless}}
`;

// Airflow 3.x DAG Template (TaskFlow API style)
const DAG_TEMPLATE_V3 = `"""
Auto-generated Airflow DAG from Control-M
Generated by OFlair
DAG: {{dag_id}}
Airflow Version: 3.x
"""

from datetime import datetime, timedelta
from airflow.sdk import DAG, Asset
from airflow.providers.standard.operators.bash import BashOperator
from airflow.providers.standard.operators.python import PythonOperator
from airflow.providers.standard.operators.empty import EmptyOperator
from airflow.providers.standard.sensors.filesystem import FileSensor

# Default arguments
default_args = {
    'owner': '{{owner}}',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': {{retries}},
    'retry_delay': timedelta(minutes={{retry_delay}}),
}

# DAG definition
with DAG(
    dag_id='{{dag_id}}',
    default_args=default_args,
    description='{{description}}',
    schedule={{schedule}},
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags={{tags}},
) as dag:

{{#each tasks}}
    # Task: {{task_id}}
{{#if is_bash}}
    {{task_id}} = BashOperator(
        task_id='{{task_id}}',
        bash_command='''{{bash_command}}''',
{{#if pool}}
        pool='{{pool}}',
{{/if}}
    )
{{/if}}
{{#if is_python}}
    {{task_id}} = PythonOperator(
        task_id='{{task_id}}',
        python_callable={{python_callable}},
{{#if pool}}
        pool='{{pool}}',
{{/if}}
    )
{{/if}}
{{#if is_sensor}}
    {{task_id}} = FileSensor(
        task_id='{{task_id}}',
        filepath='{{filepath}}',
        poke_interval=60,
        timeout=3600,
        mode='poke',
    )
{{/if}}
{{#if is_empty}}
    {{task_id}} = EmptyOperator(
        task_id='{{task_id}}',
    )
{{/if}}

{{/each}}
    # Dependencies
{{#each dependencies}}
    {{upstream}} >> {{downstream}}
{{/each}}
{{#unless dependencies}}
    # No dependencies defined
    pass
{{/unless}}
`;

// Airflow 3.x TaskFlow API Template (decorator style)
const DAG_TEMPLATE_V3_TASKFLOW = `"""
Auto-generated Airflow DAG from Control-M
Generated by OFlair (TaskFlow API)
DAG: {{dag_id}}
Airflow Version: 3.x
"""

from datetime import datetime, timedelta
from airflow.sdk import dag, task
from airflow.providers.standard.operators.bash import BashOperator
from airflow.providers.standard.operators.empty import EmptyOperator
from airflow.providers.standard.sensors.filesystem import FileSensor

default_args = {
    'owner': '{{owner}}',
    'depends_on_past': False,
    'retries': {{retries}},
    'retry_delay': timedelta(minutes={{retry_delay}}),
}

@dag(
    dag_id='{{dag_id}}',
    default_args=default_args,
    description='{{description}}',
    schedule={{schedule}},
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags={{tags}},
)
def {{dag_id}}_workflow():
    """{{description}}"""

{{#each tasks}}
{{#if is_bash}}
    {{task_id}} = BashOperator(
        task_id='{{task_id}}',
        bash_command='''{{bash_command}}''',
    )
{{/if}}
{{#if is_python}}
    @task
    def {{task_id}}_func():
        """Task: {{task_id}}"""
        # TODO: Implement python logic
        pass

    {{task_id}} = {{task_id}}_func()
{{/if}}
{{#if is_sensor}}
    {{task_id}} = FileSensor(
        task_id='{{task_id}}',
        filepath='{{filepath}}',
        poke_interval=60,
        timeout=3600,
    )
{{/if}}
{{#if is_empty}}
    {{task_id}} = EmptyOperator(
        task_id='{{task_id}}',
    )
{{/if}}

{{/each}}
    # Set dependencies
{{#each dependencies}}
    {{upstream}} >> {{downstream}}
{{/each}}

# Instantiate the DAG
{{dag_id}}_dag = {{dag_id}}_workflow()
`;

export type AirflowVersion = "2.5" | "2.6" | "2.7" | "2.8" | "2.9" | "2.10" | "3.0" | "3.1";

export interface GeneratorOptions {
  airflowVersion?: AirflowVersion;
  useTaskFlowApi?: boolean;
}

export function generateDagCode(dag: AirflowDAG, options: GeneratorOptions = {}): string {
  const { airflowVersion = "2.9", useTaskFlowApi = false } = options;

  // Select template based on version
  let templateStr: string;
  const majorVersion = parseInt(airflowVersion.split(".")[0]);

  if (majorVersion >= 3) {
    templateStr = useTaskFlowApi ? DAG_TEMPLATE_V3_TASKFLOW : DAG_TEMPLATE_V3;
  } else {
    templateStr = DAG_TEMPLATE_V2;
  }

  const template = Handlebars.compile(templateStr);

  const tasks = dag.tasks.map((task) => ({
    ...task,
    is_bash: task.operatorType === "BashOperator",
    is_python: task.operatorType === "PythonOperator",
    is_sensor: task.operatorType === "FileSensor",
    is_empty: task.operatorType === "EmptyOperator",
    bash_command: task.params.bash_command || task.params.command || "echo 'No command specified'",
    python_callable: task.params.python_callable || "lambda: None",
    filepath: task.params.filepath || "/tmp/watched_file",
    pool: task.pool,
  }));

  return template({
    dag_id: dag.dagId,
    description: dag.description || `Converted from Control-M`,
    owner: dag.defaultArgs?.owner || "airflow",
    retries: dag.defaultArgs?.retries ?? 1,
    retry_delay: dag.defaultArgs?.retryDelay ?? 5,
    schedule: dag.schedule || "None",
    tags: JSON.stringify(dag.tags || ["control-m-migration"]),
    tasks,
    dependencies: dag.dependencies,
  });
}

export function convertJobToTask(job: ControlMJob): AirflowTask {
  const taskId = toSnakeCase(job.JOBNAME);
  const jobType = (job.JOB_TYPE || "Command").toLowerCase();

  // Determine operator type based on job type
  let operatorType: AirflowTask["operatorType"] = "BashOperator";
  const params: Record<string, unknown> = {};

  if (jobType.includes("file") || jobType.includes("watcher")) {
    operatorType = "FileSensor";
    params.filepath = job.FILENAME || "/tmp/watched_file";
  } else if (jobType.includes("python") || jobType.includes("script")) {
    if (job.FILENAME?.endsWith(".py")) {
      operatorType = "PythonOperator";
      params.python_callable = `run_${taskId}`;
    } else {
      operatorType = "BashOperator";
      params.bash_command = job.CMDLINE || job.FILENAME || "echo 'No command'";
    }
  } else if (jobType === "dummy" || jobType === "box") {
    operatorType = "EmptyOperator";
  } else {
    // Default to BashOperator
    operatorType = "BashOperator";
    params.bash_command = job.CMDLINE || job.FILENAME || "echo 'No command'";
  }

  return {
    taskId,
    operatorType,
    description: job.DESCRIPTION,
    params,
    priority: job.PRIORITY ? parseInt(job.PRIORITY) : undefined,
  };
}

export function buildDependencies(jobs: ControlMJob[]): AirflowDependency[] {
  const dependencies: AirflowDependency[] = [];
  const jobNameToTaskId = new Map<string, string>();

  // Build job name to task ID mapping
  for (const job of jobs) {
    jobNameToTaskId.set(job.JOBNAME, toSnakeCase(job.JOBNAME));
  }

  // Build dependencies from INCOND (input conditions)
  for (const job of jobs) {
    const taskId = toSnakeCase(job.JOBNAME);

    if (job.INCOND) {
      for (const cond of job.INCOND) {
        // Find the job that produces this condition
        const producerJob = jobs.find(
          (j) => j.OUTCOND?.some((oc) => oc.NAME === cond.NAME)
        );

        if (producerJob) {
          const upstreamTaskId = toSnakeCase(producerJob.JOBNAME);
          // Avoid self-references
          if (upstreamTaskId !== taskId) {
            dependencies.push({
              upstream: upstreamTaskId,
              downstream: taskId,
            });
          }
        }
      }
    }
  }

  return dependencies;
}

function toSnakeCase(str: string): string {
  return str
    .replace(/([A-Z])/g, "_$1")
    .replace(/[-\s]+/g, "_")
    .replace(/^_/, "")
    .replace(/_+/g, "_")
    .toLowerCase();
}

export function groupJobsByFolder(
  jobs: ControlMJob[]
): Map<string, ControlMJob[]> {
  const groups = new Map<string, ControlMJob[]>();

  for (const job of jobs) {
    const folder = job.FOLDER_NAME || "default";
    const existing = groups.get(folder) || [];
    existing.push(job);
    groups.set(folder, existing);
  }

  return groups;
}
